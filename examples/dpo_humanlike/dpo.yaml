project: "dpo_example"
name: "trinity_dpo"
mode: train
algorithm:
  algorithm_type: dpo
  kl_loss_fn: k1
  kl_loss_fn_args:
    kl_coef: 0.1
checkpoint_root_dir: /PATH/TO/CHECKPOINT/
model:
  model_path: /PATH/TO/MODEL
  max_prompt_tokens: 512
  max_response_tokens: 1024
cluster:
  node_num: 1
  gpu_per_node: 8
buffer:
  total_epochs: 2
  batch_size: 32
  max_retry_times: 3
  max_retry_interval: 1
  trainer_input:
    experience_buffer:
      name: dpo_buffer
      storage_type: file
      enable_progress_bar: True
      path: /PATH/TO/DATASET/
      format:
        prompt_type: plaintext # plaintext/messages/chatpair
        prompt_key: prompt
        chosen_key: chosen
        rejected_key: rejected
synchronizer:
  sync_method: 'checkpoint'
  sync_interval: 30
  sync_timeout: 1200
trainer:
  trainer_type: 'verl'
  trainer_config_path: 'examples/dpo_humanlike/train_dpo.yaml'
  save_interval: 30
