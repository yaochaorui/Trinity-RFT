

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Offline DPO and SFT &mdash; Trinity-RFT 0.2.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=37f418d5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Data Processing" href="example_data_functionalities.html" />
    <link rel="prev" title="Email Search Workflow" href="example_search_email.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Trinity-RFT
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="example_reasoning_basic.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_reasoning_advanced.html">Off-Policy RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_megatron.html">Megatron-LM Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_async_mode.html">Asynchronous RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_multi_turn.html">Concatenated Multi-Turn RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_step_wise.html">General Multi-Step RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_react.html">Multi-Step ReAct</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_search_email.html">Email Search Workflow</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Offline DPO and SFT</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#step-1-model-and-data-preparation">Step 1: Model and Data Preparation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#model-preparation">Model Preparation</a></li>
<li class="toctree-l3"><a class="reference internal" href="#data-preparation">Data Preparation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#step-2-setup-configuration">Step 2: Setup Configuration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#configuration-for-dpo">Configuration for DPO</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuration-for-sft">Configuration for SFT</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#step-3-run-the-experiment">Step 3: Run the Experiment</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="example_data_functionalities.html">Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guidelines</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="trinity_programming_guide.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="trinity_configs.html">Configuration Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_mix_algo.html">Algorithm Development</a></li>
<li class="toctree-l1"><a class="reference internal" href="synchronizer.html">Synchronizer in Trinity-RFT</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_reference.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Trinity-RFT</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Offline DPO and SFT</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/modelscope/Trinity-RFT/blob/main/docs/sphinx_doc/source/tutorial/example_dpo.md" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="offline-dpo-and-sft">
<h1>Offline DPO and SFT<a class="headerlink" href="#offline-dpo-and-sft" title="Link to this heading"></a></h1>
<p>This example describes DPO and SFT based on the Qwen2.5-1.5B-Instruct model.</p>
<section id="step-1-model-and-data-preparation">
<h2>Step 1: Model and Data Preparation<a class="headerlink" href="#step-1-model-and-data-preparation" title="Link to this heading"></a></h2>
<section id="model-preparation">
<h3>Model Preparation<a class="headerlink" href="#model-preparation" title="Link to this heading"></a></h3>
<p>Download the Qwen2.5-1.5B-Instruct model to the local directory <code class="docutils literal notranslate"><span class="pre">$MODEL_PATH/Qwen2.5-1.5B-Instruct</span></code>:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using Modelscope</span>
modelscope<span class="w"> </span>download<span class="w"> </span>Qwen/Qwen2.5-1.5B-Instruct<span class="w"> </span>--local_dir<span class="w"> </span><span class="nv">$MODEL_PATH</span>/Qwen2.5-1.5B-Instruct

<span class="c1"># Using Huggingface</span>
huggingface-cli<span class="w"> </span>download<span class="w"> </span>Qwen/Qwen2.5-1.5B-Instruct<span class="w"> </span>--local-dir<span class="w"> </span><span class="nv">$MODEL_PATH</span>/Qwen2.5-1.5B-Instruct
</pre></div>
</div>
<p>More details of model downloading are referred to <a class="reference external" href="https://modelscope.cn/docs/models/download">ModelScope</a> or <a class="reference external" href="https://huggingface.co/docs/huggingface_hub/main/en/guides/cli">Huggingface</a>.</p>
</section>
<section id="data-preparation">
<h3>Data Preparation<a class="headerlink" href="#data-preparation" title="Link to this heading"></a></h3>
<p>For DPO, we download the <a class="reference external" href="https://huggingface.co/datasets/HumanLLMs/Human-Like-DPO-Dataset">Human-like-DPO-dataset</a> to the local directory <code class="docutils literal notranslate"><span class="pre">$DATASET_PATH/human_like_dpo_dataset</span></code>:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Using Modelscope</span>
modelscope<span class="w"> </span>download<span class="w"> </span>--dataset<span class="w"> </span>HumanLLMs/Human-Like-DPO-Dataset<span class="w"> </span>--local_dir<span class="w"> </span><span class="nv">$DATASET_PATH</span>/human_like_dpo_dataset

<span class="c1"># Using Huggingface</span>
huggingface-cli<span class="w"> </span>download<span class="w"> </span>HumanLLMs/Human-Like-DPO-Dataset<span class="w"> </span>--repo-type<span class="w"> </span>dataset<span class="w"> </span>--local-dir<span class="w"> </span><span class="nv">$DATASET_PATH</span>/human_like_dpo_dataset
</pre></div>
</div>
<p>Below are some data samples in JSONL format:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;prompt&quot;</span><span class="p">:</span><span class="s2">&quot;Oh, I just saw the best meme - have you seen it?&quot;</span><span class="p">,</span><span class="nt">&quot;chosen&quot;</span><span class="p">:</span><span class="s2">&quot;\ud83d\ude02 Ah, no I haven&#39;t! I&#39;m dying to know, what&#39;s the meme about? Is it a funny cat or a ridiculous situation? Spill the beans! \ud83e\udd23&quot;</span><span class="p">,</span><span class="nt">&quot;rejected&quot;</span><span class="p">:</span><span class="s2">&quot;I&#39;m an artificial intelligence language model, I don&#39;t have personal experiences or opinions. However, I can provide you with information on highly-rated and critically acclaimed films, as well as recommendations based on specific genres or themes. Would you like me to suggest some notable movies or discuss a particular genre of interest?&quot;</span><span class="p">}</span>
<span class="p">{</span><span class="nt">&quot;prompt&quot;</span><span class="p">:</span><span class="s2">&quot;Have you tried any new hobbies or activities recently?&quot;</span><span class="p">,</span><span class="nt">&quot;chosen&quot;</span><span class="p">:</span><span class="s2">&quot;You know, I&#39;ve been meaning to try my hand at gardening, but I haven&#39;t gotten around to it yet. I&#39;ve heard it&#39;s super relaxing and a great way to get some fresh air. Maybe I&#39;ll finally get around to buying some seeds and pots this weekend. What about you? Have you taken up anything new and exciting lately? \ud83c\udf31\ud83d\udc40&quot;</span><span class="p">,</span><span class="nt">&quot;rejected&quot;</span><span class="p">:</span><span class="s2">&quot;I&#39;m an artificial intelligence language model, and as such, I don&#39;t have personal experiences or engage in physical activities such as dining or cooking. My purpose is to provide information, answer questions, and assist with tasks to the best of my abilities, while maintaining a professional and impartial demeanor. If you have any specific questions or topics related to restaurants or recipes, I&#39;d be happy to provide information or guidance.&quot;</span><span class="p">}</span>
</pre></div>
</div>
<p>More details of dataset downloading are referred to <a class="reference external" href="https://modelscope.cn/docs/datasets/download">ModelScope</a> or <a class="reference external" href="https://huggingface.co/docs/huggingface_hub/main/en/guides/cli#download-a-dataset-or-a-space">Huggingface</a>.</p>
<p>Note that the dataset has the keys <code class="docutils literal notranslate"><span class="pre">prompt</span></code>, <code class="docutils literal notranslate"><span class="pre">chosen</span></code> and <code class="docutils literal notranslate"><span class="pre">rejected</span></code>. If you use different datasets, pass the proper keys to the config.</p>
<p>For SFT, we download the <code class="docutils literal notranslate"><span class="pre">open-r1/Mixture-of-Thoughts</span></code> dataset to the local directory <code class="docutils literal notranslate"><span class="pre">$DATASET_PATH/Mixture-of-Thoughts</span></code>, which contains message-based data, we list a simplified sample here.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;messages&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;You will be given a competitive programming problem...&quot;</span><span class="p">,</span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;user&quot;</span><span class="p">},{</span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;think&gt;\n...&lt;/think&gt;\n...This approach efficiently combines hashing and dynamic programming to solve the problem within the given constraints.&quot;</span><span class="p">,</span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;assistant&quot;</span><span class="p">}],</span><span class="w"> </span><span class="nt">&quot;num_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">22185</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;source&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;open-r1/codeforces-cots&quot;</span><span class="p">}</span>
</pre></div>
</div>
</section>
</section>
<section id="step-2-setup-configuration">
<h2>Step 2: Setup Configuration<a class="headerlink" href="#step-2-setup-configuration" title="Link to this heading"></a></h2>
<section id="configuration-for-dpo">
<h3>Configuration for DPO<a class="headerlink" href="#configuration-for-dpo" title="Link to this heading"></a></h3>
<p>We use the configurations in <a class="reference external" href="https://github.com/modelscope/Trinity-RFT/tree/main/examples/dpo_humanlike/dpo.yaml"><code class="docutils literal notranslate"><span class="pre">dpo.yaml</span></code></a> and <a class="reference external" href="https://github.com/modelscope/Trinity-RFT/tree/main/examples/dpo_humanlike/train_dpo.yaml"><code class="docutils literal notranslate"><span class="pre">train_dpo.yaml</span></code></a> for this experiment. Some important setups are listed in the following:</p>
<p>We run the experiment in a train mode, as there is no Explorer. To enable this mode, we config <code class="docutils literal notranslate"><span class="pre">mode</span></code> to <code class="docutils literal notranslate"><span class="pre">train</span></code> and pass the data path to the trainer.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">project</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;project_name&gt;</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;experiment_name&gt;</span>
<span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">train</span>
<span class="nt">algorithm</span><span class="p">:</span>
<span class="w">  </span><span class="nt">algorithm_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">dpo</span>
<span class="w">  </span><span class="nt">kl_loss_fn</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">k1</span>
<span class="w">  </span><span class="nt">kl_loss_fn_args</span><span class="p">:</span>
<span class="w">    </span><span class="nt">kl_coef</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span><span class="w">  </span><span class="c1"># value of beta in DPO</span>
<span class="nt">checkpoint_root_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/PATH/TO/CHECKPOINT/</span>
<span class="nt">model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">model_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">$MODEL_PATH/Qwen2.5-1.5B-Instruct</span>
<span class="nt">cluster</span><span class="p">:</span>
<span class="w">  </span><span class="nt">node_num</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">gpu_per_node</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="nt">buffer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">total_epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="w">  </span><span class="nt">train_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">64</span>
<span class="w">  </span><span class="nt">trainer_input</span><span class="p">:</span>
<span class="w">    </span><span class="nt">experience_buffer</span><span class="p">:</span>
<span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">human_like_dpo</span>
<span class="w">      </span><span class="nt">storage_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">file</span>
<span class="w">      </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">$DATASET_PATH/human_like_dpo_dataset</span>
<span class="w">      </span><span class="nt">format</span><span class="p">:</span>
<span class="w">        </span><span class="nt">prompt_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">plaintext</span>
<span class="w">        </span><span class="nt">prompt_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">prompt</span>
<span class="w">        </span><span class="nt">chosen_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">chosen</span>
<span class="w">        </span><span class="nt">rejected_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">rejected</span>
<span class="nt">trainer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">trainer_config_path</span><span class="p">:</span><span class="w"> </span><span class="s">&#39;examples/dpo_humanlike/train_dpo.yaml&#39;</span>
<span class="w">  </span><span class="nt">save_interval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">30</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">buffer.trainer_input.experience_buffer</span></code> specifies the dataset to be used for training, including its name, storage type, path, and format.</p>
<ul class="simple">
<li><p>The name <code class="docutils literal notranslate"><span class="pre">human_like_dpo</span></code> is a unique identifier for this dataset configuration, you can use other names as long as they are unique within the project.</p></li>
<li><p>The storage type <code class="docutils literal notranslate"><span class="pre">file</span></code> means the dataset is stored in a file on the local filesystem and the <code class="docutils literal notranslate"><span class="pre">path</span></code> is pointed to the local directory where the dataset is stored. Note that the <code class="docutils literal notranslate"><span class="pre">file</span></code> storage type also supports using huggingface datasets path like <code class="docutils literal notranslate"><span class="pre">HumanLLMs/Human-Like-DPO-Dataset</span></code>.</p></li>
<li><p>The format specifies how the data is structured within the dataset. In this case, it is defined as follows:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">prompt_type:</span> <span class="pre">plaintext</span></code> indicates that the prompts are in plain text format.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">prompt_key:</span> <span class="pre">prompt</span></code> specifies the key in the dataset that contains the user prompts.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">chosen_key:</span> <span class="pre">chosen</span></code> specifies the key in the dataset that contains the chosen responses.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rejected_key:</span> <span class="pre">rejected</span></code> specifies the key in the dataset that contains the rejected responses.</p></li>
</ul>
</li>
</ul>
<p>For more configuration options, please refer to the <a class="reference internal" href="trinity_configs.html#configuration-guide"><span class="std std-ref">Configuration Guide</span></a>.</p>
</section>
<section id="configuration-for-sft">
<h3>Configuration for SFT<a class="headerlink" href="#configuration-for-sft" title="Link to this heading"></a></h3>
<p>We set the <code class="docutils literal notranslate"><span class="pre">algorithm_type</span></code> as <code class="docutils literal notranslate"><span class="pre">sft</span></code> to run SFT process and then modify the config file <a class="reference external" href="https://github.com/modelscope/Trinity-RFT/tree/main/examples/sft_mot/sft.yaml"><code class="docutils literal notranslate"><span class="pre">examples/sft_mot/sft.yaml</span></code></a> with the following changes:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">project</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;project_name&gt;</span>
<span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;experiment_name&gt;</span>
<span class="nt">mode</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">train</span>
<span class="nt">algorithm</span><span class="p">:</span>
<span class="w">  </span><span class="nt">algorithm_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">sft</span>
<span class="nt">checkpoint_root_dir</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/PATH/TO/CHECKPOINT/</span>
<span class="nt">model</span><span class="p">:</span>
<span class="w">  </span><span class="nt">model_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/PATH/TO/MODEL/</span>
<span class="nt">cluster</span><span class="p">:</span>
<span class="w">  </span><span class="nt">node_num</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">  </span><span class="nt">gpu_per_node</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">2</span>
<span class="nt">buffer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">total_epochs</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">5</span>
<span class="w">  </span><span class="nt">train_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">64</span>
<span class="w">  </span><span class="nt">trainer_input</span><span class="p">:</span>
<span class="w">    </span><span class="nt">experience_buffer</span><span class="p">:</span>
<span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;sft_dataset_name&gt;</span>
<span class="w">      </span><span class="nt">storage_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">file</span>
<span class="w">      </span><span class="nt">path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">$DATASET_PATH/Mixture-of-Thoughts</span>
<span class="w">      </span><span class="nt">split</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">train</span>
<span class="w">      </span><span class="nt">format</span><span class="p">:</span>
<span class="w">        </span><span class="nt">prompt_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">messages</span>
<span class="w">        </span><span class="nt">messages_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">messages</span>
<span class="nt">trainer</span><span class="p">:</span>
<span class="w">  </span><span class="nt">trainer_config_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">/PATH/TO/TRAIN_CONFIG_YAML/</span>
<span class="w">  </span><span class="nt">save_interval</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">50</span>
</pre></div>
</div>
<p>Here we set <code class="docutils literal notranslate"><span class="pre">buffer.trainer_input.experience_buffer.format.prompt_type</span></code> to <code class="docutils literal notranslate"><span class="pre">messages</span></code> because the source data is in message format. We also set <code class="docutils literal notranslate"><span class="pre">buffer.trainer_input.experience_buffer.format.messages_key</span></code> to <code class="docutils literal notranslate"><span class="pre">messages</span></code> to specify the key in the dataset that contains the messages.</p>
</section>
</section>
<section id="step-3-run-the-experiment">
<h2>Step 3: Run the Experiment<a class="headerlink" href="#step-3-run-the-experiment" title="Link to this heading"></a></h2>
<p>Run DPO process with the following command:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>trinity<span class="w"> </span>run<span class="w"> </span>--config<span class="w"> </span>examples/dpo_humanlike/dpo.yaml
</pre></div>
</div>
<p>or, for SFT:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>trinity<span class="w"> </span>run<span class="w"> </span>--config<span class="w"> </span>examples/sft_mot/sft.yaml
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="example_search_email.html" class="btn btn-neutral float-left" title="Email Search Workflow" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="example_data_functionalities.html" class="btn btn-neutral float-right" title="Data Processing" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Trinity-RFT Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    <b>main</b>
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Branches</dt>
      <dd><b><a href="example_dpo.html">main</a> (latest)</b></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>