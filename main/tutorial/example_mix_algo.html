

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Algorithm Development &mdash; Trinity-RFT 0.2.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=37f418d5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Synchronizer in Trinity-RFT" href="synchronizer.html" />
    <link rel="prev" title="Configuration Guide" href="trinity_configs.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Trinity-RFT
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="example_reasoning_basic.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_reasoning_advanced.html">Off-Policy RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_async_mode.html">Asynchronous RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_multi_turn.html">Concatenated Multi-Turn RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_step_wise.html">General Multi-Step RFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_react.html">Multi-Step ReAct</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_search_email.html">Email Search Workflow</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_dpo.html">Offline DPO and SFT</a></li>
<li class="toctree-l1"><a class="reference internal" href="example_data_functionalities.html">Data Processing</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guidelines</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="trinity_programming_guide.html">Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="trinity_configs.html">Configuration Guide</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Algorithm Development</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#step-0-prepare-the-expert-data">Step 0: Prepare the Expert Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="#step-1-define-the-algorithm">Step 1: Define the Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="#step-2-define-the-sampling-strategy">Step 2: Define the Sampling Strategy</a></li>
<li class="toctree-l2"><a class="reference internal" href="#step-3-define-the-policy-loss-function">Step 3: Define the Policy Loss Function</a></li>
<li class="toctree-l2"><a class="reference internal" href="#step-4-run-the-experiment">Step 4: Run the Experiment</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="synchronizer.html">Synchronizer in Trinity-RFT</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">FAQ</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_reference.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Trinity-RFT</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Algorithm Development</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/modelscope/Trinity-RFT/blob/main/docs/sphinx_doc/source/tutorial/example_mix_algo.md" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="algorithm-development">
<h1>Algorithm Development<a class="headerlink" href="#algorithm-development" title="Link to this heading"></a></h1>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This guide is an advanced version of the <a class="reference internal" href="trinity_programming_guide.html#algorithms"><span class="std std-ref">Algorithms</span></a> section in the Developer Guide.</p>
</div>
<p>This guide introduces how to integrate a new algorithm to Trinity-RFT.
As an example, we incorporate some “expert” data generated by a more advanced LLM and propose an algorithm named MIX , which optimizes the following policy objective:</p>
<div class="math notranslate nohighlight">
\[
\mathcal{J}_{\text{Mix}}(\theta) =
(1-\mu) \mathcal{J}_{\text{GRPO}}(\theta)
+
\mu \cdot \underbrace{\frac{1}{B'} \sum_{b=1}^{B'}
\left[
    \frac{1}{T'_b} \sum_{t=1}^{T'_b}
    \log \pi_\theta(o'_{b,t} \mid q'_b, o'_{b,&lt;t})
\right]}_{\text{Auxiliary objective on expert data}}.
\]</div>
<p>The first term corresponds to the standard GRPO objective, which aims to maximize the expected reward. The last term is an auxiliary objective defined on expert data, encouraging the policy to imitate expert behavior. <span class="math notranslate nohighlight">\(\mu\)</span> is a weighting factor that controls the relative importance of the two terms.</p>
<p>A visualization of this pipeline is as follows:</p>
<p><img alt="" src="../_images/trinity-mix.png" /></p>
<section id="step-0-prepare-the-expert-data">
<h2>Step 0: Prepare the Expert Data<a class="headerlink" href="#step-0-prepare-the-expert-data" title="Link to this heading"></a></h2>
<p>We prompt a powerful LLM to generate responses with the CoT process for some pre-defined questions. The collected dta are viewed as some experiences from an expert. We store them in a <code class="docutils literal notranslate"><span class="pre">jsonl</span></code> file <code class="docutils literal notranslate"><span class="pre">expert_data.jsonl</span></code> with the following format:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;messages&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;system&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="err">&lt;sys</span><span class="kc">te</span><span class="err">m_promp</span><span class="kc">t</span><span class="err">&gt;</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;user&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;What is the sum of 4 and 12?&quot;</span><span class="w"> </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="w"> </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;think&gt;thinking process...&lt;/think&gt;\n&lt;answer&gt;16&lt;/answer&gt;&quot;</span><span class="w"> </span><span class="p">}</span><span class="w"> </span><span class="p">]</span>
<span class="p">},</span>
<span class="err">...</span>
</pre></div>
</div>
<p>The path to expert data is passed to <code class="docutils literal notranslate"><span class="pre">buffer.trainer_input.sft_warmup_dataset</span></code> for later use.</p>
</section>
<section id="step-1-define-the-algorithm">
<h2>Step 1: Define the Algorithm<a class="headerlink" href="#step-1-define-the-algorithm" title="Link to this heading"></a></h2>
<p>In <code class="docutils literal notranslate"><span class="pre">trinity/algorithm/algorithm.py</span></code>, we introduce a new algorithm type <code class="docutils literal notranslate"><span class="pre">MIX</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@ALGORITHM_TYPE</span><span class="o">.</span><span class="n">register_module</span><span class="p">(</span><span class="s2">&quot;mix&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MIXAlgorithm</span><span class="p">(</span><span class="n">AlgorithmType</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;MIX algorithm.&quot;&quot;&quot;</span>

    <span class="n">use_critic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">use_reference</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">compute_advantage_in_trainer</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">can_balance_batch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">schema</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;experience&quot;</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">default_config</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;repeat_times&quot;</span><span class="p">:</span> <span class="mi">8</span><span class="p">,</span>
            <span class="s2">&quot;advantage_fn&quot;</span><span class="p">:</span> <span class="s2">&quot;grpo&quot;</span><span class="p">,</span>
            <span class="s2">&quot;policy_loss_fn&quot;</span><span class="p">:</span> <span class="s2">&quot;mix&quot;</span><span class="p">,</span>
            <span class="s2">&quot;sample_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;mix&quot;</span><span class="p">,</span>
        <span class="p">}</span>
</pre></div>
</div>
</section>
<section id="step-2-define-the-sampling-strategy">
<h2>Step 2: Define the Sampling Strategy<a class="headerlink" href="#step-2-define-the-sampling-strategy" title="Link to this heading"></a></h2>
<p>We need to read two kinds of experiences: usual experiences and expert experiences in each step. For this purpose, we define a new experience sampling strategy named <code class="docutils literal notranslate"><span class="pre">MixSampleStrategy</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">class</span><span class="w"> </span><span class="nc">MixSampleStrategy</span><span class="p">(</span><span class="n">SampleStrategy</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;The default sample strategy.&quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">buffer_config</span><span class="p">:</span> <span class="n">BufferConfig</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">buffer_config</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expert_data_ratio</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;expert_data_ratio&quot;</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">tot_batch_size</span> <span class="o">=</span> <span class="n">buffer_config</span><span class="o">.</span><span class="n">train_batch_size</span>
        <span class="n">expert_batch_size</span> <span class="o">=</span> <span class="n">ceil</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">expert_data_ratio</span> <span class="o">*</span> <span class="n">tot_batch_size</span><span class="p">)</span>

        <span class="c1"># experience buffer</span>
        <span class="n">usual_buffer_config</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">buffer_config</span><span class="p">)</span>
        <span class="n">usual_buffer_config</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">=</span> <span class="n">tot_batch_size</span> <span class="o">-</span> <span class="n">expert_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">usual_exp_buffer</span> <span class="o">=</span> <span class="n">get_buffer_reader</span><span class="p">(</span>
            <span class="n">buffer_config</span><span class="o">.</span><span class="n">trainer_input</span><span class="o">.</span><span class="n">experience_buffer</span><span class="p">,</span> <span class="n">usual_buffer_config</span>  <span class="c1"># type: ignore</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="n">buffer_config</span><span class="o">.</span><span class="n">trainer_input</span><span class="o">.</span><span class="n">sft_warmup_dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;`buffer_config.trainer_input.sft_warmup_dataset` is required in MIX algorithm&quot;</span>
            <span class="p">)</span>

        <span class="c1"># expert experience buffer</span>
        <span class="n">expert_buffer_config</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">buffer_config</span><span class="p">)</span>
        <span class="n">expert_buffer_config</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">=</span> <span class="n">expert_batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">expert_exp_buffer</span> <span class="o">=</span> <span class="n">get_buffer_reader</span><span class="p">(</span>
            <span class="n">buffer_config</span><span class="o">.</span><span class="n">trainer_input</span><span class="o">.</span><span class="n">sft_warmup_dataset</span><span class="p">,</span> <span class="n">expert_buffer_config</span>
        <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">sample</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Experiences</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">]:</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="s2">&quot;read_time&quot;</span><span class="p">):</span>
            <span class="n">usual_exp_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">usual_exp_buffer</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">exp</span> <span class="ow">in</span> <span class="n">usual_exp_list</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">exp</span><span class="o">.</span><span class="n">info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">exp</span><span class="o">.</span><span class="n">info</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">exp</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;is_expert&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>

            <span class="n">expert_exp_list</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">expert_exp_buffer</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
            <span class="k">for</span> <span class="n">exp</span> <span class="ow">in</span> <span class="n">expert_exp_list</span><span class="p">:</span>
                <span class="n">exp</span><span class="o">.</span><span class="n">reward</span> <span class="o">=</span> <span class="mf">0.0</span>
                <span class="n">exp</span><span class="o">.</span><span class="n">logprobs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span>
                    <span class="n">exp</span><span class="o">.</span><span class="n">tokens</span><span class="p">[</span><span class="n">exp</span><span class="o">.</span><span class="n">prompt_length</span> <span class="p">:],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
                <span class="p">)</span>
                <span class="k">if</span> <span class="n">exp</span><span class="o">.</span><span class="n">info</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">exp</span><span class="o">.</span><span class="n">info</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="n">exp</span><span class="o">.</span><span class="n">info</span><span class="p">[</span><span class="s2">&quot;is_expert&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>

            <span class="n">exp_list</span> <span class="o">=</span> <span class="n">usual_exp_list</span> <span class="o">+</span> <span class="n">expert_exp_list</span>
            <span class="n">repr_samples</span> <span class="o">=</span> <span class="n">representative_sample</span><span class="p">(</span><span class="n">exp_list</span><span class="p">)</span>

        <span class="k">with</span> <span class="n">Timer</span><span class="p">(</span><span class="n">metrics</span><span class="p">,</span> <span class="s2">&quot;gather_time&quot;</span><span class="p">):</span>
            <span class="n">exps</span> <span class="o">=</span> <span class="n">Experiences</span><span class="o">.</span><span class="n">gather_experiences</span><span class="p">(</span>
                <span class="n">experiences</span><span class="o">=</span><span class="n">exp_list</span><span class="p">,</span>
                <span class="n">pad_token_id</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">pad_token_id</span><span class="p">,</span>  <span class="c1"># type: ignore [arg-type]</span>
                <span class="n">custom_fields</span><span class="o">=</span><span class="p">[</span>
                    <span class="n">CustomField</span><span class="p">(</span>
                        <span class="n">source_field</span><span class="o">=</span><span class="s2">&quot;is_expert&quot;</span><span class="p">,</span>
                        <span class="n">destination_field</span><span class="o">=</span><span class="s2">&quot;expert_mask&quot;</span><span class="p">,</span>
                        <span class="n">data_type</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bool</span><span class="p">,</span>
                    <span class="p">)</span>
                <span class="p">],</span>
            <span class="p">)</span>  <span class="c1"># type: ignore</span>
        <span class="k">return</span> <span class="n">exps</span><span class="p">,</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">repr_samples</span>
</pre></div>
</div>
<p>Here we use the <code class="docutils literal notranslate"><span class="pre">custom_fields</span></code> argument of <code class="docutils literal notranslate"><span class="pre">Experiences.gather_experiences</span></code> to add a new field <code class="docutils literal notranslate"><span class="pre">expert_mask</span></code>, which indicates whether the experience is from an expert or not. This field will be used in the policy loss function to distinguish between usual and expert experiences.</p>
</section>
<section id="step-3-define-the-policy-loss-function">
<h2>Step 3: Define the Policy Loss Function<a class="headerlink" href="#step-3-define-the-policy-loss-function" title="Link to this heading"></a></h2>
<p>We define a <code class="docutils literal notranslate"><span class="pre">MixPolicyLoss</span></code> class in <code class="docutils literal notranslate"><span class="pre">trinity/algorithm/policy_loss_fn/mix_policy_loss.py</span></code>, which computes the sum of two loss terms regarding usual and expert experiences, respectively.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@POLICY_LOSS_FN</span><span class="o">.</span><span class="n">register_module</span><span class="p">(</span><span class="s2">&quot;mix&quot;</span><span class="p">)</span>
<span class="k">class</span><span class="w"> </span><span class="nc">MIXPolicyLossFn</span><span class="p">(</span><span class="n">PolicyLossFn</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">backend</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;verl&quot;</span><span class="p">,</span>
        <span class="n">mu</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">clip_range</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">clip_range_low</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">clip_range_high</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">use_dynamic_bsz</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">ppo_mini_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">ppo_micro_batch_size_per_gpu</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">ngpus_trainer</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">train_batch_size_usual</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">train_batch_size_expert</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">use_token_level_loss_in_sft</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="n">backend</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">mu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">use_dynamic_bsz</span> <span class="o">=</span> <span class="n">use_dynamic_bsz</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">experience_per_gpu</span> <span class="o">=</span> <span class="n">ppo_mini_batch_size</span> <span class="o">//</span> <span class="n">ngpus_trainer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulation</span> <span class="o">=</span> <span class="n">ppo_mini_batch_size</span> <span class="o">//</span> <span class="n">ppo_micro_batch_size_per_gpu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size_usual</span> <span class="o">=</span> <span class="n">train_batch_size_usual</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size_expert</span> <span class="o">=</span> <span class="n">train_batch_size_expert</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grpo_loss_fn</span> <span class="o">=</span> <span class="n">PPOPolicyLossFn</span><span class="p">(</span>
            <span class="n">clip_range</span><span class="o">=</span><span class="n">clip_range</span><span class="p">,</span>
            <span class="n">clip_range_low</span><span class="o">=</span><span class="n">clip_range_low</span><span class="p">,</span>
            <span class="n">clip_range_high</span><span class="o">=</span><span class="n">clip_range_high</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sft_loss_fn</span> <span class="o">=</span> <span class="n">SFTLossFn</span><span class="p">(</span><span class="n">use_token_level_loss</span><span class="o">=</span><span class="n">use_token_level_loss_in_sft</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">logprob</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">old_logprob</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">action_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">advantages</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">expert_mask</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">Dict</span><span class="p">]:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">len</span><span class="p">(</span><span class="n">expert_mask</span><span class="p">)</span> <span class="o">==</span> <span class="n">logprob</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="p">),</span> <span class="sa">f</span><span class="s2">&quot;Error: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">expert_mask</span><span class="p">)</span><span class="si">=}</span><span class="s2"> != </span><span class="si">{</span><span class="n">logprob</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">=}</span><span class="s2">&quot;</span>

        <span class="n">n_usual_exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">~</span><span class="n">expert_mask</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="n">n_expert_exp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">expert_mask</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">use_dynamic_bsz</span><span class="p">:</span>
            <span class="n">per_micro_batch_weight_usual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experience_per_gpu</span> <span class="o">/</span> <span class="p">(</span>
                <span class="n">logprob</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size_usual</span>
            <span class="p">)</span>
            <span class="n">per_micro_batch_weight_expert</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">experience_per_gpu</span> <span class="o">/</span> <span class="p">(</span>
                <span class="n">logprob</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size_expert</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">per_micro_batch_weight_usual</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulation</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size_usual</span>  <span class="c1"># type: ignore</span>
            <span class="n">per_micro_batch_weight_expert</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_accumulation</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_batch_size_expert</span>  <span class="c1"># type: ignore</span>

        <span class="k">if</span> <span class="n">n_usual_exp</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">grpo_loss</span><span class="p">,</span> <span class="n">grpo_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">grpo_loss_fn</span><span class="p">(</span>
                <span class="n">logprob</span><span class="p">[</span><span class="o">~</span><span class="n">expert_mask</span><span class="p">],</span>
                <span class="n">old_logprob</span><span class="p">[</span><span class="o">~</span><span class="n">expert_mask</span><span class="p">],</span>
                <span class="n">action_mask</span><span class="p">[</span><span class="o">~</span><span class="n">expert_mask</span><span class="p">],</span>
                <span class="n">advantages</span><span class="p">[</span><span class="o">~</span><span class="n">expert_mask</span><span class="p">],</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">grpo_loss</span> <span class="o">=</span> <span class="n">grpo_loss</span> <span class="o">*</span> <span class="n">n_usual_exp</span> <span class="o">*</span> <span class="n">per_micro_batch_weight_usual</span>
            <span class="n">grpo_metrics</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="o">*</span> <span class="n">n_usual_exp</span> <span class="o">*</span> <span class="n">per_micro_batch_weight_usual</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">grpo_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">grpo_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">logprob</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">grpo_metrics</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="c1"># SFT Loss (expert)</span>
        <span class="k">if</span> <span class="n">n_expert_exp</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">sft_loss</span><span class="p">,</span> <span class="n">sft_metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sft_loss_fn</span><span class="p">(</span>
                <span class="n">logprob</span><span class="p">[</span><span class="n">expert_mask</span><span class="p">],</span>
                <span class="n">action_mask</span><span class="p">[</span><span class="n">expert_mask</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">sft_loss</span> <span class="o">=</span> <span class="n">sft_loss</span> <span class="o">*</span> <span class="n">n_expert_exp</span> <span class="o">*</span> <span class="n">per_micro_batch_weight_expert</span>
            <span class="n">sft_metrics</span> <span class="o">=</span> <span class="p">{</span>
                <span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="o">*</span> <span class="n">n_expert_exp</span> <span class="o">*</span> <span class="n">per_micro_batch_weight_expert</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sft_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
            <span class="p">}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">sft_loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">logprob</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
            <span class="n">sft_metrics</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">)</span> <span class="o">*</span> <span class="n">grpo_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">*</span> <span class="n">sft_loss</span>

        <span class="n">metrics</span> <span class="o">=</span> <span class="p">{</span><span class="sa">f</span><span class="s2">&quot;usual/</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">grpo_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="sa">f</span><span class="s2">&quot;expert/</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">sft_metrics</span><span class="o">.</span><span class="n">items</span><span class="p">()})</span>
        <span class="n">metrics</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;loss&quot;</span><span class="p">:</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()})</span>

        <span class="k">return</span> <span class="n">loss</span><span class="p">,</span> <span class="n">metrics</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">default_args</span><span class="p">(</span><span class="bp">cls</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">&quot;mu&quot;</span><span class="p">:</span> <span class="mf">0.1</span><span class="p">,</span>
            <span class="s2">&quot;clip_range&quot;</span><span class="p">:</span> <span class="mf">0.2</span><span class="p">,</span>
        <span class="p">}</span>
</pre></div>
</div>
</section>
<section id="step-4-run-the-experiment">
<h2>Step 4: Run the Experiment<a class="headerlink" href="#step-4-run-the-experiment" title="Link to this heading"></a></h2>
<p>With the above newly-defined classes and functions, we can run the experiments without modifying other process.
An example showing some important configurations is shown below, including the weighting factor <span class="math notranslate nohighlight">\(\mu\)</span> as <code class="docutils literal notranslate"><span class="pre">algorithm.policy_loss_fn_args['mu']</span></code> and the batch size of expert experiences <span class="math notranslate nohighlight">\(B'\)</span>, calculated as the product of <code class="docutils literal notranslate"><span class="pre">buffer.batch_size</span></code>, <code class="docutils literal notranslate"><span class="pre">algorithm.sample_strategy_args['expert_data_ratio']</span></code> and <code class="docutils literal notranslate"><span class="pre">algorithm.repeat_times</span></code>.
For the full configuration, please refer to <a class="reference external" href="https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_math/mix_math.yaml"><code class="docutils literal notranslate"><span class="pre">mix_math.yaml</span></code></a> and <a class="reference external" href="https://github.com/modelscope/Trinity-RFT/tree/main/examples/mix_math/train_mix_math.yaml"><code class="docutils literal notranslate"><span class="pre">train_mix_math.yaml</span></code></a>.</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">algorithm</span><span class="p">:</span>
<span class="w">  </span><span class="nt">algorithm_type</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mix</span>
<span class="w">  </span><span class="nt">repeat_times</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">  </span><span class="nt">sample_strategy_args</span><span class="p">:</span>
<span class="w">    </span><span class="nt">expert_data_ratio</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.25</span>
<span class="w">  </span><span class="nt">policy_loss_fn_args</span><span class="p">:</span>
<span class="w">    </span><span class="nt">mu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.1</span>
<span class="w">    </span><span class="nt">clip_range</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">0.2</span>
<span class="w">    </span><span class="nt">use_token_level_loss_in_sft</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">    </span><span class="nt">use_dynamic_bsz</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">False</span>
<span class="w">    </span><span class="nt">repeat_times</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">8</span>
<span class="w">    </span><span class="nt">ppo_mini_batch_size</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">256</span>
<span class="w">    </span><span class="nt">ppo_micro_batch_size_per_gpu</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">    </span><span class="nt">ngpus_trainer</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">4</span>
<span class="w">    </span><span class="nt">train_batch_size_expert</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">64</span>
<span class="w">    </span><span class="nt">train_batch_size_usual</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">192</span>
</pre></div>
</div>
<p>With the above configurations, the experiment can be run with the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>trinity<span class="w"> </span>run<span class="w"> </span>--config<span class="w"> </span>examples/mix_math/mix_math.yaml
</pre></div>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="trinity_configs.html" class="btn btn-neutral float-left" title="Configuration Guide" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="synchronizer.html" class="btn btn-neutral float-right" title="Synchronizer in Trinity-RFT" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Trinity-RFT Team.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    <b>main</b>
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Branches</dt>
      <dd><b><a href="example_mix_algo.html">main</a> (latest)</b></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>