"""Launch the trainer"""

import argparse

import ray

from trinity.common.config import Config, load_config
from trinity.common.constants import AlgorithmType
from trinity.explorer.explorer import Explorer
from trinity.trainer.trainer import Trainer
from trinity.utils.log import get_logger

logger = get_logger(__name__)


def explore(config: Config) -> None:
    """Run explorer."""
    explorer = Explorer.remote(config)
    try:
        ray.get(explorer.prepare.remote())
        ray.get(explorer.sync_weight.remote())
        ref, _ = ray.wait([explorer.explore.remote()])
        ray.get(ref)
        logger.info("Explore finished.")
    except Exception as e:
        logger.error(f"Explore failed: {e}")
        raise e


def train(config: Config) -> None:
    """Run trainer."""

    algo_type = config.trainer.algorithm_type
    trainer = Trainer.remote(config)
    try:
        ray.get(trainer.prepare.remote())
        ref, _ = ray.wait([trainer.train.remote(algo_type)])
        ray.get(ref)
        logger.info("Train finished.")
    except Exception as e:
        logger.error(f"Train failed {e}.")
        raise e


def both(config: Config) -> None:
    """Setup both explorer and trainer.

    For the explorer, a step contains `batch_size * sync_iteration_interval` number
    of rollout tasks.

    For the trainer, it has to consume all experiences generated by the explorer in
    the latest step. The specific number of experiences may vary for different
    algorithms and tasks.
    """
    explorer = Explorer.remote(config)
    trainer = Trainer.remote(config)
    ray.get([explorer.__ray_ready__.remote(), trainer.__ray_ready__.remote()])
    logger.info("Setup explorer and trainer finished.")
    ray.get(
        [
            explorer.prepare.remote(),
            trainer.prepare.remote(),
        ]
    )
    # sync weight before training start
    ray.get([explorer.sync_weight.remote(), trainer.sync_weight.remote()])

    if config.trainer.sft_warmup_iteration > 0:
        for step in range(config.trainer.sft_warmup_iteration):
            ray.get([trainer.train_step.remote(AlgorithmType.SFT)])
            logger.info(f"SFT warmup step {step} finished.")
        ray.get([explorer.sync_weight.remote(), trainer.sync_weight.remote()])

    algo_type = config.trainer.algorithm_type
    global_iter_num = 0
    while True:
        try:
            explore_continue = explorer.explore_step.remote()
            train_continue = trainer.train_step.remote(algo_type)
            if not ray.get(explore_continue):
                logger.info("Explorer finished, stopping...")
                break
            if not ray.get(train_continue):
                logger.info("Trainer finished, stopping...")
                break
            ray.get([explorer.sync_weight.remote(), trainer.sync_weight.remote()])
            logger.info("Model weight synchronized.")
        except Exception as e:
            logger.error(e)
            logger.error("Training stopped due to exception.")
            raise e
        global_iter_num += 1
        if global_iter_num % config.trainer.eval_interval == 0:
            ray.wait([explorer.eval.remote()])
            logger.info("Eval step finished.")


def main() -> None:
    """The main entrypoint."""
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers(dest="command", required=True)

    # run command
    run_parser = subparsers.add_parser("run", help="Run RFT process.")
    run_parser.add_argument("--config", type=str, required=True, help="config file path.")

    # TODO: add more commands like `monitor`, `label`

    args = parser.parse_args()
    if args.command == "run":
        # TODO: support parse all args from command line
        config = load_config(args.config)
        config.check_and_update()
        ray.init()
        if config.mode == "explore":
            explore(config)
        elif config.mode == "train":
            train(config)
        elif config.mode == "both":
            both(config)


if __name__ == "__main__":
    main()
